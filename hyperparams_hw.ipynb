{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "\n",
       "[2 rows x 1777 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/molecular_activity.csv')\n",
    "display(df.head(2))\n",
    "\n",
    "X, y = df.drop('Activity', axis=1), df['Activity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSeachCV (lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7819790828640387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver': ['sag', 'saga'],\n",
    "    'C': [0.01, 0.3, 0.7, 1]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=1, max_iter=50), \n",
    "    param_grid=param_grid, cv=5, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train) \n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print(f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV (lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7819790828640387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(random_state=1, max_iter=50), \n",
    "    param_distributions=param_grid, cv=5, n_iter=10, n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print(f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt (rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPE is being used as the default algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:19<00:00,  1.59s/trial, best loss: -0.9932838458819372]\n",
      "0.8168557536466774\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, Trials\n",
    "import numpy as np\n",
    "\n",
    "def hyperopt_rf(params, X=X_train, y=y_train):\n",
    "    params = {\n",
    "        'n_estimators': int(params['n_estimators']), \n",
    "        'max_depth': int(params['max_depth']), \n",
    "        'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "    }\n",
    "    rf = RandomForestClassifier(**params, random_state=1)\n",
    "    rf.fit(X, y)\n",
    "    return -f1_score(y, rf.predict(X))\n",
    "\n",
    "trials = Trials()\n",
    "space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "    'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "}\n",
    "best = fmin(hyperopt_rf, space=space, max_evals=50, trials=trials) #, rstate=np.random.RandomState(1))\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    random_state=1, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna (rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-05 02:02:57,212]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:02:58,325]\u001b[0m Trial 0 finished with value: 0.9618747813920951 and parameters: {'n_estimators': 102, 'max_depth': 21, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9618747813920951.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:02:59,789]\u001b[0m Trial 1 finished with value: 0.9925768822905621 and parameters: {'n_estimators': 120, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:00,791]\u001b[0m Trial 2 finished with value: 0.9012905476107429 and parameters: {'n_estimators': 103, 'max_depth': 20, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:02,081]\u001b[0m Trial 3 finished with value: 0.9034965034965035 and parameters: {'n_estimators': 117, 'max_depth': 20, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:03,864]\u001b[0m Trial 4 finished with value: 0.9883515707730322 and parameters: {'n_estimators': 126, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:05,674]\u001b[0m Trial 5 finished with value: 0.9175977653631284 and parameters: {'n_estimators': 194, 'max_depth': 14, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:07,155]\u001b[0m Trial 6 finished with value: 0.8988136775994418 and parameters: {'n_estimators': 165, 'max_depth': 21, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:09,104]\u001b[0m Trial 7 finished with value: 0.9241523942677385 and parameters: {'n_estimators': 196, 'max_depth': 29, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:10,280]\u001b[0m Trial 8 finished with value: 0.942577030812325 and parameters: {'n_estimators': 110, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:12,284]\u001b[0m Trial 9 finished with value: 0.9897562698693041 and parameters: {'n_estimators': 171, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:13,746]\u001b[0m Trial 10 finished with value: 0.9590766002098636 and parameters: {'n_estimators': 136, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.9925768822905621.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:15,702]\u001b[0m Trial 11 finished with value: 0.9932885906040269 and parameters: {'n_estimators': 163, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:17,330]\u001b[0m Trial 12 finished with value: 0.9774647887323944 and parameters: {'n_estimators': 150, 'max_depth': 26, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:19,083]\u001b[0m Trial 13 finished with value: 0.9925821264570823 and parameters: {'n_estimators': 145, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:20,692]\u001b[0m Trial 14 finished with value: 0.9596915527514897 and parameters: {'n_estimators': 153, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:22,458]\u001b[0m Trial 15 finished with value: 0.9329608938547487 and parameters: {'n_estimators': 178, 'max_depth': 24, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:23,922]\u001b[0m Trial 16 finished with value: 0.9369306236860547 and parameters: {'n_estimators': 141, 'max_depth': 11, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:25,711]\u001b[0m Trial 17 finished with value: 0.9774489076814658 and parameters: {'n_estimators': 160, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:27,204]\u001b[0m Trial 18 finished with value: 0.9464473223661184 and parameters: {'n_estimators': 143, 'max_depth': 27, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:28,855]\u001b[0m Trial 19 finished with value: 0.9165794066317626 and parameters: {'n_estimators': 180, 'max_depth': 23, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:30,163]\u001b[0m Trial 20 finished with value: 0.9415879678209165 and parameters: {'n_estimators': 130, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:31,630]\u001b[0m Trial 21 finished with value: 0.9922206506364922 and parameters: {'n_estimators': 122, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9932885906040269.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:33,441]\u001b[0m Trial 22 finished with value: 0.9936395759717315 and parameters: {'n_estimators': 152, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:35,185]\u001b[0m Trial 23 finished with value: 0.9777934437786394 and parameters: {'n_estimators': 154, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:37,115]\u001b[0m Trial 24 finished with value: 0.9929378531073447 and parameters: {'n_estimators': 165, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:39,239]\u001b[0m Trial 25 finished with value: 0.9777777777777777 and parameters: {'n_estimators': 186, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:40,964]\u001b[0m Trial 26 finished with value: 0.96 and parameters: {'n_estimators': 165, 'max_depth': 22, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:43,028]\u001b[0m Trial 27 finished with value: 0.9936395759717315 and parameters: {'n_estimators': 174, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:45,129]\u001b[0m Trial 28 finished with value: 0.9774330042313116 and parameters: {'n_estimators': 186, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:47,050]\u001b[0m Trial 29 finished with value: 0.96044802240112 and parameters: {'n_estimators': 159, 'max_depth': 29, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:48,833]\u001b[0m Trial 30 finished with value: 0.933705512909979 and parameters: {'n_estimators': 173, 'max_depth': 23, 'min_samples_leaf': 6}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:51,031]\u001b[0m Trial 31 finished with value: 0.9932933286268972 and parameters: {'n_estimators': 167, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:53,076]\u001b[0m Trial 32 finished with value: 0.9932885906040269 and parameters: {'n_estimators': 170, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:55,297]\u001b[0m Trial 33 finished with value: 0.9932885906040269 and parameters: {'n_estimators': 176, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:57,260]\u001b[0m Trial 34 finished with value: 0.978122794636556 and parameters: {'n_estimators': 179, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:03:59,170]\u001b[0m Trial 35 finished with value: 0.9932838458819372 and parameters: {'n_estimators': 188, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:00,829]\u001b[0m Trial 36 finished with value: 0.9604203152364272 and parameters: {'n_estimators': 174, 'max_depth': 29, 'min_samples_leaf': 4}. Best is trial 22 with value: 0.9936395759717315.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:02,503]\u001b[0m Trial 37 finished with value: 0.9939908094733122 and parameters: {'n_estimators': 156, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.9939908094733122.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:03,960]\u001b[0m Trial 38 finished with value: 0.976056338028169 and parameters: {'n_estimators': 158, 'max_depth': 21, 'min_samples_leaf': 3}. Best is trial 37 with value: 0.9939908094733122.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:05,143]\u001b[0m Trial 39 finished with value: 0.907627711686494 and parameters: {'n_estimators': 147, 'max_depth': 26, 'min_samples_leaf': 9}. Best is trial 37 with value: 0.9939908094733122.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:06,424]\u001b[0m Trial 40 finished with value: 0.9462592202318231 and parameters: {'n_estimators': 134, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 37 with value: 0.9939908094733122.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:08,065]\u001b[0m Trial 41 finished with value: 0.9936440677966101 and parameters: {'n_estimators': 169, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.9939908094733122.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:09,613]\u001b[0m Trial 42 finished with value: 0.9939908094733122 and parameters: {'n_estimators': 154, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 37 with value: 0.9939908094733122.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:11,372]\u001b[0m Trial 43 finished with value: 0.99434628975265 and parameters: {'n_estimators': 155, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:12,817]\u001b[0m Trial 44 finished with value: 0.9781382228490832 and parameters: {'n_estimators': 157, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:14,327]\u001b[0m Trial 45 finished with value: 0.9939908094733122 and parameters: {'n_estimators': 153, 'max_depth': 29, 'min_samples_leaf': 2}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:15,827]\u001b[0m Trial 46 finished with value: 0.9922206506364922 and parameters: {'n_estimators': 140, 'max_depth': 29, 'min_samples_leaf': 2}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:17,264]\u001b[0m Trial 47 finished with value: 0.9753347427766033 and parameters: {'n_estimators': 148, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:18,611]\u001b[0m Trial 48 finished with value: 0.9583187390542907 and parameters: {'n_estimators': 155, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n",
      "\u001b[32m[I 2022-06-05 02:04:20,015]\u001b[0m Trial 49 finished with value: 0.9633802816901408 and parameters: {'n_estimators': 161, 'max_depth': 14, 'min_samples_leaf': 3}. Best is trial 43 with value: 0.99434628975265.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8168557536466774\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def optuna_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "study.optimize(optuna_rf, n_trials=50)\n",
    "\n",
    "rf = RandomForestClassifier(**study.best_params,random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(f1_score(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
